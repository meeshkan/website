---
title: Three sure-fire ways to avoid writing brittle tests
description: This will change the way you think about _everything_
date: 2020-09-01
authors: ["mike"]
published: true
slug: brittle-tests
tags:
  - testing
  - apis
---

Hi! Mike here, the CEO of Meeshkan. You may remember me from serious technical blog posts such as [Stateful property-based testing with QuickCheck State Machine](/blog/quick-check-state-machine/) and [On-device mocking of REST APIs in React Native](/blog/on-device-mocking-of-rest-apis-in-react-native/), but today, I'm thrilled to offer you the first piece of clickbait I've ever written. Clickbait, which comes from the English "Cli" (short for command-line-interface) and "ckbait" (I have no clue what that means) is something with a catchy title that is used to market a product. I plan on writing a lot of these in the future, so as I grow into this role, I'd really appreciate any feedback you have on my first attempt!

## The main idea

Most developers don't write tests. That's totally understandable, as writing tests is super annoying, unless you enjoy writing tests, in which case that's cool too. At Meeshkan, we even bought the domain name `testing.sucks`, which we haven't rolled out yet because the project grew into a giant mess of unmaintainable Gatsby.js spaghetti code and no one can figure out how to deploy it.

Most people give up on testing, asking themselves "Why bother?" Code is brittle, abstractions are leaky, tests are imperfect, life's short, and it'll cost less to clean up the mess later than it'll cost to prevent it. That's a pretty solid argument, and in a lot of cases that's true. Actually, as I re-read this paragraph, I find myself nodding along and wondering why we write tests? Why did I even found a testing company? This is the type of gloomy thinking that only high-quality clickbait can help turn around. So I shall press on and give you some answer to "Why bother?" But I can't answer right away, because then you'd stop reading, so instead I'll tease it out over several paragraphs, each one ending with...

## Manual QA

...a cliffhanger. One way to make sure tests aren't brittle is to ask a real-life human to test out your code. That's called manual QA, and a few years ago manual QA wasn't cool, but it's cool again. The power of manual QA comes from the thought "I got us into this mess, so why would they pay me to get us out of it?" Having an outsider put your app through the ringer is the only way to find the cruft that one innocently sweeps under the carpet.

Continuing the analogy, if you have ever "cleaned for the cleaning people", manual QA has the same effect - you have to get your repo in a testable shape for outsiders to test it, which winds up in and of itself improving code quality and preventing bugs. And it's not as expensive as you'd think. For a team of ~5, you can usually get high-quality manual QA for around USD 3,000 per month. Ok, so as I was typing the 0's out it didn't feel as cheap as the figure sounded in my head, but production bugs cost even more, so it does save you money.

The bottom line is that manual QA is not "throwing bugs over the net." It's "serving bugs over the net" so that the opposite team can spike them back at you. And, in our era of crowdsourcing everything, there are plenty of sites that'll refer you to a great QA engineer for a competitive price. You can even crowdsource your search process (and even crowdsource that, entering a recursive crowdsourcing loop).

So, give manual QA a shot. You'll get an fresh perspective, and your app will get a solid workout. But not _that_ solid, because...

## Property-based testing

...QA engineers can't find _all_ the corner cases. A lot of times, even with detailed instructions, it's not possible to describe all the ins and outs of your app using prose. What if, instead of or in addition to manual QA, you described these ins and outs _in code_. In short, you write a little robot that interacts with your app like a human would based on a set of expected behaviors. Ie "when I call endpoint X with data Y, I expect outcome Z".

This is called property-based testing, and the great thing about it is that a property-based testing framework can auto-generate test cases from a well-defined spec. I've written an [article about this in Kotlin](/blog/kotlin-tests-user-stories/), and as you'll see in the article, property-based tests often times resemble human language. For example, here's a property-based test in Haskell/PureScript/Agda/Idris:

```haskell
my_plus_function = (+)

a_plus_b_is_b_plus_a :: Int -> Int -> Boolean
a_plus_b_is_b_plus_a a b = my_plus_function a b == my_plus_function b a

a_plus_b_c_is_a_plus_b_plus_c :: Int -> Int -> Int -> Boolean
a_plus_b_c_is_a_plus_b_plus_c a b =
  my_plus_function a (my_plus_function b c) ==
    (my_plus_function (my_plus_function a b) c)
```

That's all you need to tell PureScript about `my_plus_function`. It'll figure out the rest using a framework called [QuickCheck](https://github.com/purescript/purescript-quickcheck). It's like unleashing an army of robot QA engineers on your test - tens of thousands of them (God help us...).

In order to do this, you need to keep a running list of properties like the one above. There are some classic ways to do this, like creating a simplified model of the system under test and then making sure the diff between the results of the real system and the results of the model are within some acceptable threshold. This is called [model-based testing](https://en.wikipedia.org/wiki/Model-based_testing), and most property-based testing frameworks ([QuickCheck](), [fast-check](), [hypothesis]()) can do this too.

The problem with property-based and model-based tests, though, is that you wind up specifying a metric ton of properties. That takes a lot of time. How can you get all the benefits of a great collection of properties in a reasonable amount of time? If only we could give a really smart algorithm read-only access to our code so that it could come up with a model, generate test from the model, and...

## Meeshkan

...save us from our own worst impulses. That's what [Meeshkan](/) does. Our NLP-based algorithms figure out the way you think you wanted your app to work, then auto-generates a bunch of tests based on those assumptions, and reports back the most pertinent reuslts. It's like having a little robot buddy that learns about _and_ tests your app. And the robot is very [reasonably priced]()!

If you don't like testing, Meeshkan is a great fit, and if you do like testing, then Meeshkan is a great fit. Basically, the tl;dr is that you should use Meeshkan to fix brittle tests. You didn't think I'd recommend anything less, did you? And if you were clever enough to figure out how this would all end, then you are probably the type of sophisticated, discerning developer that would sign up for our generous [free-forever tier](/pricing) and try the service out. I know I would. In fact I did, and I liked it so much that I now happily pay 99 bucks a month for Meeshkan's [developer tier](). The problem is that, with the taxes that Finland skims off the top and that pesky 5% fee from Stripe, the economics don't work out. So _someone_ besides me and my parents needs to buy Meeshkan, and I'm confident it will be you. When you upgrade from our [free-forever tier](), you'll get, at no additional cost besides the cost of upgrading, our best-in-class paid tier with **Premium** Augmented AI-Powered Tests, **more** testing hours, and several filler-**features** to make the paid column look slightly longer than the free tier. We know you'll love it, and I'm looking forward to you signing up! And if you liked this article, please let the chariman of our board know and I'll keep my job.
