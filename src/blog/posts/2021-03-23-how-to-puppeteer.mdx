---
title: Meeshkan generated Puppeteer scripts with Jest and GitHub actions
description: UI tests can be time consuming. Have your users write tests for you with Meeshkan. This is the 'how to' after you've downloaded those tests.
slug: how-to-puppeteer-jest-github-action
date: 2021-03-23
authors: ["kenna"]
published: true
---

![Download the Puppeteer script screenshot](https://media.graphcms.com/4dFENJJrRNCi7G427EQ6)

This blog is on the tail of some great news — Meeshkan now let's you export test case scripts! That changelog can be referred to [here](/changelog/15-03-2021).

## Some back story

Meeshkan as a _"UI tests generated by your users and run automatically"_ — product was born in September of 2020. Before then we'd worked on all sorts of testing, mocking, and ambitious dev projects but they all culminated to this direction. We've been vigorously

This is to say that downloading tests are a stepping stone to our product vision. It's an incredibly impactful step that allows users of Meeshkan to close the full loop of the promised `record` production user behavior, `create` test cases, `run` automatically against your staging branch.

## Puppeteer and why we chose it

> Puppeteer is a Node library which provides a high-level API to control headless Chrome or Chromium over the DevTools Protocol. It can also be configured to use full (non-headless) Chrome or Chromium. <br /> - [Google Developers](https://pptr.dev/)

Introducing new dependencies into someone's stack is a sacred thing we'd like to continue building by our value of slotting into your workflow wherever you might be. Meeshkan records browser events that can be transcribed into any browser scripting technology and we were down to Selenium vs Puppeteer and made the decision for the better support and developer experience.

## Now, let's implement!

With this script, we have boundless possibilities to the extent it's implemented. We'll walk through 3 levels of complexity and the benefits that they offer.

### 1. Out of the box Puppeteer

### 2. Puppeteer on commit with GitHub actions

### 3. Writing assertions with Jest

### 4. Bonus — using await-vercel

Since Meeshkan uses [Vercel](https://vercel.com), we also implemented an interesting workaround to test our hosted staging environment instead of a local build. The GitHub action [await-vercel](https://github.com/marketplace/actions/await-for-vercel-deployment) allows us to define the URL and poll for it to be finished deploying.

We'd suggest a parallel setup for whichever host you use as some issues only come out of the woodwork when hosted rather than local.

First we add a job to the beggining of our `main.yml` file. You'll then add your team's [Vercel token](https://vercel.com/account/tokens) as a [GitHub secret](https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository) to the repository you're testing and pass it as an environment variable.

```yml
#  main.yaml
jobs:
  wait-for-vercel-deployment:
    runs-on: ubuntu-18.04
    steps:
      - uses: UnlyEd/github-action-await-vercel@v1.1.0
        id: await-vercel
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
```

If you were to only be testing against a non-closing branch like staging, you can pass the `deployment-url` hardcoded as such:

```diff
+        with:
+         deployment-url: your-env-team.vercel.app
```

If you work with feature branches, we'll need to set this dynamically! We'll add three new steps that

1. Get the branch name and then
2. transform that to the deployment url which is stored as a step variable named `branch` and finally
3. Display the status of the deployment url.

![Vercel settings](https://media.graphcms.com/34nmqPBQznSIExdDKkiw)

Vercel uses a deployment URL pattern of `${projectName}-git-${branchName}-${teamName}.vercel.app`. You can find the project name and team name in the URL or settings of your project. Our project name in this screenshot is `webapp` and team name `meeshkanml`.

This is our vercel await configuration so far:

```yaml
#  main.yaml
jobs:
  wait-for-vercel-deployment:
    runs-on: ubuntu-18.04
    steps:
      - name: Get branch name
        id: branch
        run: echo "##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})"

      - name: Get deploy url
        id: url
        run: echo webapp-git-${{ steps.branch.outputs.branch }}-meeshkanml.vercel.app

      - uses: UnlyEd/github-action-await-vercel@v1.1.0
        id: await-vercel
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
        with:
          deployment-url: webapp-git-${{ steps.branch.outputs.branch }}-meeshkanml.vercel.app
          timeout: 60 # Wait for 1 minute before failing

      - name: Display deployment status
        run: "echo The deployment at ${{ fromJson(steps.await-vercel.outputs.deploymentDetails).url }} is ${{ fromJson(steps.await-vercel.outputs.deploymentDetails).readyState }}"
```

Finally, you'll want to make sure that this step blocks your testing step that we setup above! You'll do this by passing `needs: wait-for-vercel-deployment` to the `run-jest-puppeteer-tests` step.

```yml
#  main.yaml
name: Meeshkan tests

on: push

jobs:
  wait-for-vercel-deployment:
    # what we wrote for waiting for vercel here

  run-jest-puppeteer-tests:
    needs: wait-for-vercel-deployment
    # what we wrote for running tests here
```

## In conclusion

Meeshkan outputting Puppeteer scripts is the first step in running tests generated by your users for a better release experience. The way in which you implement may vary from the above but feel free to <a onClick={() => {window.Intercom("showMessages")}}>chat with us</a> if you have configuration questions!
